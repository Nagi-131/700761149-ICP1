{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyML6QZVc+Wz4AJcHO12M8v6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagi-131/700761149-ICP1/blob/main/700761149%20ICP3\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBDne_1rY4sA",
        "outputId": "71b6b8ed-7f37-42ea-daab-b88057ccf7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 4ms/step - loss: 4.3687 - acc: 0.5330\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0006 - acc: 0.5677\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3870 - acc: 0.6007\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2321 - acc: 0.6233\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0929 - acc: 0.5764\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0021 - acc: 0.5851\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9403 - acc: 0.5885\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9144 - acc: 0.6042\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8663 - acc: 0.6163\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8240 - acc: 0.6198\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7985 - acc: 0.6285\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8040 - acc: 0.6267\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7573 - acc: 0.6354\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7418 - acc: 0.6389\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7305 - acc: 0.6510\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7197 - acc: 0.6354\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7258 - acc: 0.6372\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6878 - acc: 0.6406\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6680 - acc: 0.6597\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.6545\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6621 - acc: 0.6545\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6497 - acc: 0.6632\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6330 - acc: 0.6771\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6381 - acc: 0.6719\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6380 - acc: 0.6615\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6246 - acc: 0.6771\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6231 - acc: 0.6910\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6206 - acc: 0.6806\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6140 - acc: 0.6753\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6370 - acc: 0.6736\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6046 - acc: 0.6771\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6069 - acc: 0.6771\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6039 - acc: 0.6806\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6062 - acc: 0.6910\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6165 - acc: 0.6875\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6236 - acc: 0.6753\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6005 - acc: 0.6927\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6002 - acc: 0.6840\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6115 - acc: 0.6632\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6274 - acc: 0.6736\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6223 - acc: 0.6892\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5969 - acc: 0.7066\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5900 - acc: 0.7031\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6077 - acc: 0.6823\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5953 - acc: 0.6892\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5926 - acc: 0.6753\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5859 - acc: 0.7101\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5862 - acc: 0.7014\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5905 - acc: 0.7014\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5896 - acc: 0.6840\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5858 - acc: 0.6962\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5765 - acc: 0.7031\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5835 - acc: 0.6823\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6061 - acc: 0.6736\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5793 - acc: 0.7014\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5839 - acc: 0.6823\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5847 - acc: 0.7014\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6245 - acc: 0.6823\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6090 - acc: 0.6806\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6163 - acc: 0.6667\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6046 - acc: 0.6736\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5688 - acc: 0.7083\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5727 - acc: 0.7049\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - acc: 0.7101\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5671 - acc: 0.7153\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5720 - acc: 0.7101\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5710 - acc: 0.7083\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5691 - acc: 0.7153\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5653 - acc: 0.7188\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5641 - acc: 0.7222\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5620 - acc: 0.7049\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5605 - acc: 0.7222\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - acc: 0.7153\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5928 - acc: 0.6927\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5664 - acc: 0.7014\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5593 - acc: 0.7292\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - acc: 0.7205\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5632 - acc: 0.7170\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5866 - acc: 0.6962\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5826 - acc: 0.6753\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5834 - acc: 0.7049\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5584 - acc: 0.7240\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5608 - acc: 0.7222\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5641 - acc: 0.7188\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5548 - acc: 0.7188\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5679 - acc: 0.7170\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5698 - acc: 0.7118\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5762 - acc: 0.6892\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5540 - acc: 0.7292\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5565 - acc: 0.7205\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - acc: 0.7118\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5514 - acc: 0.7083\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5530 - acc: 0.7361\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5754 - acc: 0.7153\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5541 - acc: 0.7326\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - acc: 0.7188\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5677 - acc: 0.7083\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5705 - acc: 0.7309\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5666 - acc: 0.7118\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - acc: 0.7222\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                180       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201 (804.00 Byte)\n",
            "Trainable params: 201 (804.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6030 - acc: 0.6458\n",
            "[0.6030148267745972, 0.6458333134651184]\n"
          ]
        }
      ],
      "source": [
        "# Predicting the diabetes disease\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Mounted at /content/gdrive\n",
        "\n",
        "path_to_csv = '/content/sample_data/diabetes.csv'\n",
        "\n",
        "\n",
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer with input\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BEUybJSaNPv",
        "outputId": "97ddc3c6-2cdd-4b4d-c9c9-f12e7f4ab25d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 20)                180       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2301 (8.99 KB)\n",
            "Trainable params: 2301 (8.99 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5675 - acc: 0.7448\n",
            "[0.5674752593040466, 0.7447916865348816]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/sample_data/breastcancer.csv'\n",
        "\n",
        "#Importing packages for creating arrays\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Importing packages to convert Categorical data into Numerical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Importing packages for splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Importing packages for keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "\n",
        "#Loading the Dataset\n",
        "dataset = pd.read_csv(path_to_csv, header=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "ylI782TZaVpv",
        "outputId": "18229e72-769f-49dc-fab6-b4d2e33c939e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0      842302         M        17.99         10.38          122.80     1001.0   \n",
              "1      842517         M        20.57         17.77          132.90     1326.0   \n",
              "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3    84348301         M        11.42         20.38           77.58      386.1   \n",
              "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
              "..        ...       ...          ...           ...             ...        ...   \n",
              "564    926424         M        21.56         22.39          142.00     1479.0   \n",
              "565    926682         M        20.13         28.25          131.20     1261.0   \n",
              "566    926954         M        16.60         28.08          108.30      858.1   \n",
              "567    927241         M        20.60         29.33          140.10     1265.0   \n",
              "568     92751         B         7.76         24.54           47.92      181.0   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.11840           0.27760         0.30010              0.14710   \n",
              "1            0.08474           0.07864         0.08690              0.07017   \n",
              "2            0.10960           0.15990         0.19740              0.12790   \n",
              "3            0.14250           0.28390         0.24140              0.10520   \n",
              "4            0.10030           0.13280         0.19800              0.10430   \n",
              "..               ...               ...             ...                  ...   \n",
              "564          0.11100           0.11590         0.24390              0.13890   \n",
              "565          0.09780           0.10340         0.14400              0.09791   \n",
              "566          0.08455           0.10230         0.09251              0.05302   \n",
              "567          0.11780           0.27700         0.35140              0.15200   \n",
              "568          0.05263           0.04362         0.00000              0.00000   \n",
              "\n",
              "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0    ...          17.33           184.60      2019.0           0.16220   \n",
              "1    ...          23.41           158.80      1956.0           0.12380   \n",
              "2    ...          25.53           152.50      1709.0           0.14440   \n",
              "3    ...          26.50            98.87       567.7           0.20980   \n",
              "4    ...          16.67           152.20      1575.0           0.13740   \n",
              "..   ...            ...              ...         ...               ...   \n",
              "564  ...          26.40           166.10      2027.0           0.14100   \n",
              "565  ...          38.25           155.00      1731.0           0.11660   \n",
              "566  ...          34.12           126.70      1124.0           0.11390   \n",
              "567  ...          39.42           184.60      1821.0           0.16500   \n",
              "568  ...          30.37            59.16       268.6           0.08996   \n",
              "\n",
              "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0              0.66560           0.7119                0.2654          0.4601   \n",
              "1              0.18660           0.2416                0.1860          0.2750   \n",
              "2              0.42450           0.4504                0.2430          0.3613   \n",
              "3              0.86630           0.6869                0.2575          0.6638   \n",
              "4              0.20500           0.4000                0.1625          0.2364   \n",
              "..                 ...              ...                   ...             ...   \n",
              "564            0.21130           0.4107                0.2216          0.2060   \n",
              "565            0.19220           0.3215                0.1628          0.2572   \n",
              "566            0.30940           0.3403                0.1418          0.2218   \n",
              "567            0.86810           0.9387                0.2650          0.4087   \n",
              "568            0.06444           0.0000                0.0000          0.2871   \n",
              "\n",
              "     fractal_dimension_worst  Unnamed: 32  \n",
              "0                    0.11890          NaN  \n",
              "1                    0.08902          NaN  \n",
              "2                    0.08758          NaN  \n",
              "3                    0.17300          NaN  \n",
              "4                    0.07678          NaN  \n",
              "..                       ...          ...  \n",
              "564                  0.07115          NaN  \n",
              "565                  0.06637          NaN  \n",
              "566                  0.07820          NaN  \n",
              "567                  0.12400          NaN  \n",
              "568                  0.07039          NaN  \n",
              "\n",
              "[569 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7e30cb5-5a3b-4160-8b5b-dbbe75fcfa40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7e30cb5-5a3b-4160-8b5b-dbbe75fcfa40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7e30cb5-5a3b-4160-8b5b-dbbe75fcfa40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7e30cb5-5a3b-4160-8b5b-dbbe75fcfa40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d2696fe-78a9-44e7-90fb-999e02a496f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d2696fe-78a9-44e7-90fb-999e02a496f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d2696fe-78a9-44e7-90fb-999e02a496f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b0917a61-b17a-4ba2-b36d-1001b9f2b68f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b0917a61-b17a-4ba2-b36d-1001b9f2b68f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Categorical data into Numerical Using Label Encoding\n",
        "le=LabelEncoder()\n",
        "dataset['diagnosis'] = le.fit_transform(dataset['diagnosis'])\n",
        "\n",
        "\n",
        "dataset.info()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psH3uwK_akOl",
        "outputId": "aa84fffe-08cc-4548-e5ab-5765fc63ad2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    int64  \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(2)\n",
            "memory usage: 146.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data into Feature Matrix & Label Matrix\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset.iloc[:,2:32], dataset.iloc[:,1], test_size=0.25, random_state=87)\n",
        "\n",
        "\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TkKBFdfav_s",
        "outputId": "6dc5672c-7b3c-41d3-ace2-f2f1d07ef4a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1481 (5.79 KB)\n",
            "Trainable params: 1481 (5.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3325 - acc: 0.8601\n",
            "[0.332499235868454, 0.8601398468017578]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages for Normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "\n",
        "sc = StandardScaler() #Create Model\n",
        "X_train = sc.fit_transform(X_train) #Fit to data, then transform it.\n",
        "X_test = sc.transform(X_test) # Perform standardization by centering and scaling\n",
        "\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pliI05_BbQks",
        "outputId": "da1df29e-7987-4947-b8ea-059619c20191"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_17 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641 (2.50 KB)\n",
            "Trainable params: 641 (2.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1752 - acc: 0.9580\n",
            "[0.17517751455307007, 0.9580419659614563]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAYsgQhAbcKz",
        "outputId": "0fd93eed-1a75-46eb-8499-395b052d6290"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "6bdub2D2Y8Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ3bMIrMctYL",
        "outputId": "07d15491-8152-42fc-a4cc-71c0800fd1ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2942 - accuracy: 0.9090 - val_loss: 0.1271 - val_accuracy: 0.9600\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.1008 - accuracy: 0.9692 - val_loss: 0.0976 - val_accuracy: 0.9684\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0632 - accuracy: 0.9801 - val_loss: 0.0982 - val_accuracy: 0.9684\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.0805 - val_accuracy: 0.9750\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.0699 - val_accuracy: 0.9792\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0603 - val_accuracy: 0.9831\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0632 - val_accuracy: 0.9817\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0636 - val_accuracy: 0.9823\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0672 - val_accuracy: 0.9825\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0860 - val_accuracy: 0.9794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))\n",
        "\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI1xP35KdGAx",
        "outputId": "99358f7f-0e3f-4655-b4bd-8a644dfec6eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0860 - accuracy: 0.9794\n",
            "Evaluation result on Test Data : Loss = 0.08604460209608078, accuracy = 0.9793999791145325\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'val_accuracy','loss','val_loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "2BjrCVVSdml8",
        "outputId": "36a10f27-749a-4aab-91b1-5a75acb65e87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_data[0].reshape(28,28))\n",
        "print(\"predicted label:\",model.predict(test_data[0].reshape(1,784)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "jlcoRrPadt_N",
        "outputId": "f379a02f-c53a-4c7e-ea42-ef420e9a2082"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 273ms/step\n",
            "predicted label: [[3.0081911e-12 4.5435135e-11 1.1547230e-10 4.8474824e-10 4.7214159e-15\n",
            "  1.2507322e-13 4.4747827e-17 1.0000000e+00 2.4376215e-13 1.0026597e-09]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. We had used 2 hidden layers and Relu activation. Try to change the number of hidden layer and the activation to tanh or sigmoid and see what happens.\n",
        "\n",
        "#increasing the number of hidden layers to 6\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss1, test_acc1] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data with 4 hidden layers: Loss = {}, accuracy = {}\".format(test_loss1, test_acc1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuES63sIdylb",
        "outputId": "ed15d834-cbd5-43fd-daf0-c34ed1002416"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 20s 82ms/step - loss: 0.4600 - accuracy: 0.8580 - val_loss: 0.2236 - val_accuracy: 0.9367\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 18s 76ms/step - loss: 0.1279 - accuracy: 0.9627 - val_loss: 0.2159 - val_accuracy: 0.9325\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.0791 - accuracy: 0.9767 - val_loss: 0.1358 - val_accuracy: 0.9643\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0585 - accuracy: 0.9829 - val_loss: 0.1071 - val_accuracy: 0.9711\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.0835 - val_accuracy: 0.9777\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 0.1252 - val_accuracy: 0.9661\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 18s 76ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0776 - val_accuracy: 0.9793\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.1057 - val_accuracy: 0.9771\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0846 - val_accuracy: 0.9813\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 18s 78ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0765 - val_accuracy: 0.9816\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0765 - accuracy: 0.9816\n",
            "Evaluation result on Test Data with 4 hidden layers: Loss = 0.07653012126684189, accuracy = 0.9815999865531921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the same code without scaling the images and check the performance?\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "# print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss3, test_acc3] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data without scaling: Loss = {}, accuracy = {}\".format(test_loss3, test_acc3))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NU8X6vyevdf",
        "outputId": "2d6f33a5-82da-4bbb-c885-f82145841bce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 10s 39ms/step - loss: 6.8624 - accuracy: 0.8740 - val_loss: 1.1644 - val_accuracy: 0.8910\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.4565 - accuracy: 0.9477 - val_loss: 0.5017 - val_accuracy: 0.9403\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.2734 - accuracy: 0.9582 - val_loss: 0.3856 - val_accuracy: 0.9412\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1915 - accuracy: 0.9668 - val_loss: 0.2389 - val_accuracy: 0.9614\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.1618 - accuracy: 0.9710 - val_loss: 0.3078 - val_accuracy: 0.9562\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.1409 - accuracy: 0.9757 - val_loss: 0.3400 - val_accuracy: 0.9544\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.1356 - accuracy: 0.9791 - val_loss: 0.3398 - val_accuracy: 0.9644\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.1245 - accuracy: 0.9814 - val_loss: 0.3450 - val_accuracy: 0.9689\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1249 - accuracy: 0.9826 - val_loss: 0.4512 - val_accuracy: 0.9633\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.1099 - accuracy: 0.9843 - val_loss: 0.2900 - val_accuracy: 0.9710\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2900 - accuracy: 0.9710\n",
            "Evaluation result on Test Data without scaling: Loss = 0.2899666726589203, accuracy = 0.9710000157356262\n"
          ]
        }
      ]
    }
  ]
}